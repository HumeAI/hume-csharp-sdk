using System.Text.Json;
using System.Text.Json.Serialization;
using HumeApi;
using HumeApi.Core;

namespace HumeApi.EmpathicVoice;

/// <summary>
/// A description of a single event in a chat returned from the server
/// </summary>
[Serializable]
public record ReturnChatEvent : IJsonOnDeserialized
{
    [JsonExtensionData]
    private readonly IDictionary<string, JsonElement> _extensionData =
        new Dictionary<string, JsonElement>();

    /// <summary>
    /// Identifier for a Chat Event. Formatted as a UUID.
    /// </summary>
    [JsonPropertyName("id")]
    public required string Id { get; set; }

    /// <summary>
    /// Identifier for the Chat this event occurred in. Formatted as a UUID.
    /// </summary>
    [JsonPropertyName("chat_id")]
    public required string ChatId { get; set; }

    /// <summary>
    /// Time at which the Chat Event occurred. Measured in seconds since the Unix epoch.
    /// </summary>
    [JsonPropertyName("timestamp")]
    public required long Timestamp { get; set; }

    /// <summary>
    /// The role of the entity which generated the Chat Event. There are four possible values:
    ///
    /// - `USER`: The user, capable of sending user messages and interruptions.
    ///
    /// - `AGENT`: The assistant, capable of sending agent messages.
    ///
    /// - `SYSTEM`: The backend server, capable of transmitting errors.
    ///
    /// - `TOOL`: The function calling mechanism.
    /// </summary>
    [JsonPropertyName("role")]
    public required ReturnChatEventRole Role { get; set; }

    /// <summary>
    /// Type of Chat Event. There are six possible values:
    ///
    /// - `SYSTEM_PROMPT`: Contains the system prompt for use in the session.
    ///
    /// - `USER_MESSAGE`: Contains the message sent by the user.
    ///
    /// - `USER_INTERRUPTION`: Contains an interruption made by the user while the agent is speaking.
    ///
    /// - `AGENT_MESSAGE`: Contains the assistant’s message, generated by Hume’s eLLM and supplemental LLM.
    ///
    /// - `FUNCTION_CALL`: Contains the invocation of a tool.
    ///
    /// - `FUNCTION_CALL_RESPONSE`: Contains the tool response.
    /// </summary>
    [JsonPropertyName("type")]
    public required ReturnChatEventType Type { get; set; }

    /// <summary>
    /// The text of the Chat Event. This field contains the message content for each event type listed in the `type` field.
    /// </summary>
    [JsonPropertyName("message_text")]
    public string? MessageText { get; set; }

    /// <summary>
    /// Stringified JSON containing the prosody model inference results.
    ///
    /// EVI uses the prosody model to measure 48 expressions related to speech and vocal characteristics. These results contain a detailed emotional and tonal analysis of the audio. Scores typically range from 0 to 1, with higher values indicating a stronger confidence level in the measured attribute.
    /// </summary>
    [JsonPropertyName("emotion_features")]
    public string? EmotionFeatures { get; set; }

    /// <summary>
    /// Stringified JSON with additional metadata about the chat event.
    /// </summary>
    [JsonPropertyName("metadata")]
    public string? Metadata { get; set; }

    [JsonIgnore]
    public ReadOnlyAdditionalProperties AdditionalProperties { get; private set; } = new();

    void IJsonOnDeserialized.OnDeserialized() =>
        AdditionalProperties.CopyFromExtensionData(_extensionData);

    /// <inheritdoc />
    public override string ToString()
    {
        return JsonUtils.Serialize(this);
    }
}
